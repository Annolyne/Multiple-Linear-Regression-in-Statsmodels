{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression in Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lecture, you'll learn how to run your first multiple linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Introduce Statsmodels for multiple regression\n",
    "* Present alternatives for running regression in Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statsmodels for multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture will be more of a code-along, where we will walk through a multiple linear regression model using both Statsmodels and Scikit-Learn. \n",
    "\n",
    "Remember that we introduced single linear regression before, which is known as ordinary least squares. It determines a line of best fit by minimizing the sum of squares of the errors between the models predictions and the actual data. In algebra and statistics classes, this is often limited to the simple 2 variable case of $y=mx+b$, but this process can be generalized to use multiple predictive variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-mpg data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below reiterates the steps we've taken before: we've created dummies for our categorical variables and have log-transformed some of our continuous predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"auto-mpg.csv\") \n",
    "data['horsepower'].astype(str).astype(int)\n",
    "\n",
    "acc = data[\"acceleration\"]\n",
    "logdisp = np.log(data[\"displacement\"])\n",
    "loghorse = np.log(data[\"horsepower\"])\n",
    "logweight= np.log(data[\"weight\"])\n",
    "\n",
    "scaled_acc = (acc-min(acc))/(max(acc)-min(acc))\t\n",
    "scaled_disp = (logdisp-np.mean(logdisp))/np.sqrt(np.var(logdisp))\n",
    "scaled_horse = (loghorse-np.mean(loghorse))/(max(loghorse)-min(loghorse))\n",
    "scaled_weight= (logweight-np.mean(logweight))/np.sqrt(np.var(logweight))\n",
    "\n",
    "data_fin = pd.DataFrame([])\n",
    "data_fin[\"acc\"]= scaled_acc\n",
    "data_fin[\"disp\"]= scaled_disp\n",
    "data_fin[\"horse\"] = scaled_horse\n",
    "data_fin[\"weight\"] = scaled_weight\n",
    "cyl_dummies = pd.get_dummies(data[\"cylinders\"], prefix=\"cyl\")\n",
    "yr_dummies = pd.get_dummies(data[\"model year\"], prefix=\"yr\")\n",
    "orig_dummies = pd.get_dummies(data[\"origin\"], prefix=\"orig\")\n",
    "mpg = data[\"mpg\"]\n",
    "data_fin = pd.concat([mpg, data_fin, cyl_dummies, yr_dummies, orig_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 392 entries, 0 to 391\n",
      "Data columns (total 26 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   mpg     392 non-null    float64\n",
      " 1   acc     392 non-null    float64\n",
      " 2   disp    392 non-null    float64\n",
      " 3   horse   392 non-null    float64\n",
      " 4   weight  392 non-null    float64\n",
      " 5   cyl_3   392 non-null    uint8  \n",
      " 6   cyl_4   392 non-null    uint8  \n",
      " 7   cyl_5   392 non-null    uint8  \n",
      " 8   cyl_6   392 non-null    uint8  \n",
      " 9   cyl_8   392 non-null    uint8  \n",
      " 10  yr_70   392 non-null    uint8  \n",
      " 11  yr_71   392 non-null    uint8  \n",
      " 12  yr_72   392 non-null    uint8  \n",
      " 13  yr_73   392 non-null    uint8  \n",
      " 14  yr_74   392 non-null    uint8  \n",
      " 15  yr_75   392 non-null    uint8  \n",
      " 16  yr_76   392 non-null    uint8  \n",
      " 17  yr_77   392 non-null    uint8  \n",
      " 18  yr_78   392 non-null    uint8  \n",
      " 19  yr_79   392 non-null    uint8  \n",
      " 20  yr_80   392 non-null    uint8  \n",
      " 21  yr_81   392 non-null    uint8  \n",
      " 22  yr_82   392 non-null    uint8  \n",
      " 23  orig_1  392 non-null    uint8  \n",
      " 24  orig_2  392 non-null    uint8  \n",
      " 25  orig_3  392 non-null    uint8  \n",
      "dtypes: float64(5), uint8(21)\n",
      "memory usage: 23.5 KB\n"
     ]
    }
   ],
   "source": [
    "data_fin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the data we had until now. As we want to focus on model interpretation and still don't want to have a massive model for now, let's only inlude \"acc\", \"horse\" and the three \"orig\" categories in our final data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>weight</th>\n",
       "      <th>orig_1</th>\n",
       "      <th>orig_2</th>\n",
       "      <th>orig_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.720986</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.908047</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.651205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.648095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.664652</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  acceleration    weight  orig_1  orig_2  orig_3\n",
       "0  18.0      0.238095  0.720986       1       0       0\n",
       "1  15.0      0.208333  0.908047       1       0       0\n",
       "2  18.0      0.178571  0.651205       1       0       0\n",
       "3  16.0      0.238095  0.648095       1       0       0\n",
       "4  17.0      0.148810  0.664652       1       0       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ols = pd.concat([mpg, scaled_acc, scaled_weight, orig_dummies], axis= 1)\n",
    "data_ols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the statsmodels.api to run our ols on all our data. Just like for linear regression with a single predictor, you can use the formula $y \\sim X$, where, with $n$ predictors, X is represented as $x_1+\\ldots+x_n$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"mpg ~ acceleration+weight+orig_1+orig_2+orig_3\"\n",
    "model = ols(formula= formula, data=data_ols).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to type out all the predictors isn't practical when you have many. Another better way than to type them all out is to seperate out the outcome variable \"mpg\" out of your data frame, and use the a `\"+\".join()` command on the predictors, as done below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'mpg'\n",
    "predictors = data_ols.drop('mpg', axis=1)\n",
    "pred_sum = \"+\".join(predictors.columns)\n",
    "formula = outcome + \"~\" + pred_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   256.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 23 Jul 2024</td> <th>  Prob (F-statistic):</th> <td>1.86e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:14:44</td>     <th>  Log-Likelihood:    </th> <td> -1107.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2224.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   16.1041</td> <td>    0.509</td> <td>   31.636</td> <td> 0.000</td> <td>   15.103</td> <td>   17.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    5.0494</td> <td>    1.389</td> <td>    3.634</td> <td> 0.000</td> <td>    2.318</td> <td>    7.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -5.8764</td> <td>    0.282</td> <td>  -20.831</td> <td> 0.000</td> <td>   -6.431</td> <td>   -5.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_1</th>       <td>    4.6566</td> <td>    0.363</td> <td>   12.839</td> <td> 0.000</td> <td>    3.944</td> <td>    5.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_2</th>       <td>    5.0690</td> <td>    0.454</td> <td>   11.176</td> <td> 0.000</td> <td>    4.177</td> <td>    5.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_3</th>       <td>    6.3785</td> <td>    0.430</td> <td>   14.829</td> <td> 0.000</td> <td>    5.533</td> <td>    7.224</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.427</td> <th>  Durbin-Watson:     </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.648</td> <th>  Prob(JB):          </th> <td>6.95e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.322</td> <th>  Cond. No.          </th> <td>5.47e+15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.24e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.726\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     256.7\n",
       "Date:                Tue, 23 Jul 2024   Prob (F-statistic):          1.86e-107\n",
       "Time:                        21:14:44   Log-Likelihood:                -1107.2\n",
       "No. Observations:                 392   AIC:                             2224.\n",
       "Df Residuals:                     387   BIC:                             2244.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       16.1041      0.509     31.636      0.000      15.103      17.105\n",
       "acceleration     5.0494      1.389      3.634      0.000       2.318       7.781\n",
       "weight          -5.8764      0.282    -20.831      0.000      -6.431      -5.322\n",
       "orig_1           4.6566      0.363     12.839      0.000       3.944       5.370\n",
       "orig_2           5.0690      0.454     11.176      0.000       4.177       5.961\n",
       "orig_3           6.3785      0.430     14.829      0.000       5.533       7.224\n",
       "==============================================================================\n",
       "Omnibus:                       37.427   Durbin-Watson:                   0.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.989\n",
       "Skew:                           0.648   Prob(JB):                     6.95e-13\n",
       "Kurtosis:                       4.322   Cond. No.                     5.47e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.24e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(formula= formula, data=data_ols).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even easier, simply use the `.OLS`-method from statsmodels.api. The advantage is that you don't have to create the summation string. Important to note, however, is that the intercept term is not included by default, so you have to make sure you manipulate your `predictors` dataframe so it inclused a constant term. You can do this using `.add_constant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   256.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 23 Jul 2024</td> <th>  Prob (F-statistic):</th> <td>1.86e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:14:51</td>     <th>  Log-Likelihood:    </th> <td> -1107.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2224.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   16.1041</td> <td>    0.509</td> <td>   31.636</td> <td> 0.000</td> <td>   15.103</td> <td>   17.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    5.0494</td> <td>    1.389</td> <td>    3.634</td> <td> 0.000</td> <td>    2.318</td> <td>    7.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -5.8764</td> <td>    0.282</td> <td>  -20.831</td> <td> 0.000</td> <td>   -6.431</td> <td>   -5.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_1</th>       <td>    4.6566</td> <td>    0.363</td> <td>   12.839</td> <td> 0.000</td> <td>    3.944</td> <td>    5.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_2</th>       <td>    5.0690</td> <td>    0.454</td> <td>   11.176</td> <td> 0.000</td> <td>    4.177</td> <td>    5.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_3</th>       <td>    6.3785</td> <td>    0.430</td> <td>   14.829</td> <td> 0.000</td> <td>    5.533</td> <td>    7.224</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.427</td> <th>  Durbin-Watson:     </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.648</td> <th>  Prob(JB):          </th> <td>6.95e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.322</td> <th>  Cond. No.          </th> <td>5.47e+15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.24e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.726\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     256.7\n",
       "Date:                Tue, 23 Jul 2024   Prob (F-statistic):          1.86e-107\n",
       "Time:                        21:14:51   Log-Likelihood:                -1107.2\n",
       "No. Observations:                 392   AIC:                             2224.\n",
       "Df Residuals:                     387   BIC:                             2244.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           16.1041      0.509     31.636      0.000      15.103      17.105\n",
       "acceleration     5.0494      1.389      3.634      0.000       2.318       7.781\n",
       "weight          -5.8764      0.282    -20.831      0.000      -6.431      -5.322\n",
       "orig_1           4.6566      0.363     12.839      0.000       3.944       5.370\n",
       "orig_2           5.0690      0.454     11.176      0.000       4.177       5.961\n",
       "orig_3           6.3785      0.430     14.829      0.000       5.533       7.224\n",
       "==============================================================================\n",
       "Omnibus:                       37.427   Durbin-Watson:                   0.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.989\n",
       "Skew:                           0.648   Prob(JB):                     6.95e-13\n",
       "Kurtosis:                       4.322   Cond. No.                     5.47e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.24e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "predictors_int = sm.add_constant(predictors)\n",
    "model = sm.OLS(data['mpg'],predictors_int).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like for single multiple regression, the coefficients for our model should be interpreted as \"how does Y change for each additional unit X\"? Do note that the fact that we transformed X, interpretation can sometimes require a little more attention. In fact, as the model is built on the transformed X, the actual relationship is \"how does Y change for each additional unit X'\", where X' is the (log- and min-max, standardized,...) transformed data matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also repeat this process using Scikit-Learn. The code to do this can be found below. Scikit-learn is very popular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_ols['mpg']\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(predictors, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.04941007, -5.87640551, -0.71140721, -0.29903267,  1.01043987])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.47216428607542"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intercept\n",
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are the coefficients diff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = predictors.drop(\"orig_3\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.04941007, -5.87640551, -1.72184708, -1.30947254])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit(predictors, y)\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.482604160455686"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.723</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   256.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 23 Jul 2024</td> <th>  Prob (F-statistic):</th> <td>1.86e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:15:19</td>     <th>  Log-Likelihood:    </th> <td> -1107.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2224.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   387</td>      <th>  BIC:               </th> <td>   2244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   22.4826</td> <td>    0.789</td> <td>   28.504</td> <td> 0.000</td> <td>   20.932</td> <td>   24.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    5.0494</td> <td>    1.389</td> <td>    3.634</td> <td> 0.000</td> <td>    2.318</td> <td>    7.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -5.8764</td> <td>    0.282</td> <td>  -20.831</td> <td> 0.000</td> <td>   -6.431</td> <td>   -5.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_1</th>       <td>   -1.7218</td> <td>    0.653</td> <td>   -2.638</td> <td> 0.009</td> <td>   -3.005</td> <td>   -0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orig_2</th>       <td>   -1.3095</td> <td>    0.688</td> <td>   -1.903</td> <td> 0.058</td> <td>   -2.662</td> <td>    0.043</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.427</td> <th>  Durbin-Watson:     </th> <td>   0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.648</td> <th>  Prob(JB):          </th> <td>6.95e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.322</td> <th>  Cond. No.          </th> <td>    9.59</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.726\n",
       "Model:                            OLS   Adj. R-squared:                  0.723\n",
       "Method:                 Least Squares   F-statistic:                     256.7\n",
       "Date:                Tue, 23 Jul 2024   Prob (F-statistic):          1.86e-107\n",
       "Time:                        21:15:19   Log-Likelihood:                -1107.2\n",
       "No. Observations:                 392   AIC:                             2224.\n",
       "Df Residuals:                     387   BIC:                             2244.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       22.4826      0.789     28.504      0.000      20.932      24.033\n",
       "acceleration     5.0494      1.389      3.634      0.000       2.318       7.781\n",
       "weight          -5.8764      0.282    -20.831      0.000      -6.431      -5.322\n",
       "orig_1          -1.7218      0.653     -2.638      0.009      -3.005      -0.438\n",
       "orig_2          -1.3095      0.688     -1.903      0.058      -2.662       0.043\n",
       "==============================================================================\n",
       "Omnibus:                       37.427   Durbin-Watson:                   0.840\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.989\n",
       "Skew:                           0.648   Prob(JB):                     6.95e-13\n",
       "Kurtosis:                       4.322   Cond. No.                         9.59\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sum = \"+\".join(predictors.columns)\n",
    "formula = outcome + \"~\" + pred_sum\n",
    "model = ols(formula= formula, data=data_ols).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  LSTAT                          with p-value 5.0811e-88\n",
      "Add  RM                             with p-value 3.47226e-27\n",
      "Add  PTRATIO                        with p-value 1.64466e-14\n",
      "Add  DIS                            with p-value 1.66847e-05\n",
      "Add  NOX                            with p-value 5.48815e-08\n",
      "Add  CHAS                           with p-value 0.000265473\n",
      "Add  B                              with p-value 0.000771946\n",
      "Add  ZN                             with p-value 0.00465162\n",
      "resulting features:\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = load_boston()\n",
    "boston_pred = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "boston_target = data.target\n",
    "\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "result = stepwise_selection(boston_pred,boston_target)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/937/does-scikit-learn-have-forward-selection-stepwise-regression-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  weight                         with p-value 1.16293e-107\n",
      "Add  acceleration                   with p-value 0.000646572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n",
      "<ipython-input-17-113e393a937a>:35: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_pval = pd.Series(index=excluded)\n"
     ]
    }
   ],
   "source": [
    "result = stepwise_selection(predictors, y, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acceleration</th>\n",
       "      <th>weight</th>\n",
       "      <th>orig_1</th>\n",
       "      <th>orig_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.720986</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.908047</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.651205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.648095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.664652</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.452381</td>\n",
       "      <td>-0.090383</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.988095</td>\n",
       "      <td>-1.051504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.785832</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.630952</td>\n",
       "      <td>-0.307450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.678571</td>\n",
       "      <td>-0.180861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acceleration    weight  orig_1  orig_2\n",
       "0        0.238095  0.720986       1       0\n",
       "1        0.208333  0.908047       1       0\n",
       "2        0.178571  0.651205       1       0\n",
       "3        0.238095  0.648095       1       0\n",
       "4        0.148810  0.664652       1       0\n",
       "..            ...       ...     ...     ...\n",
       "387      0.452381 -0.090383       1       0\n",
       "388      0.988095 -1.051504       0       1\n",
       "389      0.214286 -0.785832       1       0\n",
       "390      0.630952 -0.307450       1       0\n",
       "391      0.678571 -0.180861       1       0\n",
       "\n",
       "[392 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
